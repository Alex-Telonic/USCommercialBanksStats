{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'callreports_final.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ac07f4725ba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmlt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"callreports_final.dta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator)\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0morder_categoricals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder_categoricals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\stata.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buf, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m             \u001b[1;31m# Copy to BytesIO, and ensure no encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'callreports_final.dta'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlt\n",
    "\n",
    "data = pd.read_stata(\"callreports_final.dta\", chunksize=100000, preserve_dtypes=True)\n",
    "\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "for chunk in data:\n",
    "    df_raw=df_raw.append(chunk)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "from matplotlib import ticker\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import cm\n",
    "import datetime\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\"\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "SMALL_SIZE = 8\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 18\n",
    "\n",
    "#setting matplotlib style\n",
    "plt.style.use('default')\n",
    "\n",
    "#setting params for matplolib plots\n",
    "plt.rcParams['font.size']=BIGGER_SIZE          # controls default text sizes\n",
    "plt.rcParams['axes.titlesize']=BIGGER_SIZE     # fontsize of the axes title\n",
    "plt.rcParams['axes.labelsize']=BIGGER_SIZE    # fontsize of the x and y labels\n",
    "plt.rcParams['xtick.labelsize']=BIGGER_SIZE    # fontsize of the tick labels\n",
    "plt.rcParams['ytick.labelsize']=BIGGER_SIZE    # fontsize of the tick labels\n",
    "plt.rcParams['legend.fontsize']=BIGGER_SIZE    # legend fontsize\n",
    "plt.rcParams['figure.titlesize']=BIGGER_SIZE  # fontsize of the figure title\n",
    "plt.rcParams['xtick.bottom']=True  # fontsize of the figure title\n",
    "plt.rcParams['xtick.major.bottom']=True  # fontsize of the figure title\n",
    "plt.rcParams['xtick.major.size']=3.5  # fontsize of the figure title\n",
    "#plt.rcParams['xtick.major.width']=1  # fontsize of the figure title\n",
    "plt.rcParams['xtick.major.top']=False  # fontsize of the figure title\n",
    "plt.rcParams['xtick.minor.bottom']=True  # fontsize of the figure title\n",
    "plt.rcParams['xtick.minor.size']=3  # fontsize of the figure title\n",
    "#plt.rcParams['legend.fontsize'] = 22\n",
    "\n",
    "#setting grid style\n",
    "plt.rcParams['grid.color'] = 'k'\n",
    "plt.rcParams['grid.linestyle'] = ':'\n",
    "plt.rcParams['grid.linewidth'] = 0.5\n",
    "\n",
    "#figsizes\n",
    "figsize_OneGraph=(20,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structural adjustments on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[df_raw.name.str.startswith(\"JP\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing investment banks Goldman Sachs and Morgan Stanley\n",
    "df_raw = df_raw[(df_raw.rssdid!=1456501) & (df_raw.bhcid!=2380443)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"date\"] = pd.to_datetime(df_raw.date, format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeseries labels for xaxis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) for year in range(1976, 2014)]\n",
    "\n",
    "years16 = [str(year) for year in range(1976, 2014, 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for plotting crisis shades on graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_crisis(ax):\n",
    "    #1980Q1-Q3 crisis\n",
    "    ax.axvspan(16, 19, alpha=0.5, color='gray')\n",
    "\n",
    "\n",
    "    #1981Q3-1982Q4 crisis\n",
    "    ax.axvspan(22, 27, alpha=0.5, color='gray')\n",
    "\n",
    "    #1990Q3-1991Q2 crisis\n",
    "    ax.axvspan(58, 61, alpha=0.5, color='gray')\n",
    "\n",
    "    #2001Q2-2001Q4 crisis\n",
    "    ax.axvspan(101, 103, alpha=0.5, color='gray')\n",
    "\n",
    "    #2007Q4-2009Q3 crisis\n",
    "    ax.axvspan(127, 134, alpha=0.5, color='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes xaxis with datetime objects\n",
    "'''\n",
    "def plot_crisis_datetime(ax):\n",
    "    #1980 crisis\n",
    "    ax.axvspan(datetime.datetime(1980,3,31), datetime.datetime(1980,9,30), alpha=0.5, color='gray')\n",
    "    \n",
    "    \n",
    "    #1981Q3-1982Q4 crisis\n",
    "    ax.axvspan(datetime.datetime(1981,9,30), datetime.datetime(1982,12,31), alpha=0.5, color='gray')\n",
    "    \n",
    "    #1990Q3-1991Q2 crisis\n",
    "    ax.axvspan(datetime.datetime(1990,9,30), datetime.datetime(1991,6,30), alpha=0.5, color='gray')\n",
    "    \n",
    "    #2001Q2-2001Q4 crisis\n",
    "    ax.axvspan(datetime.datetime(2001,6,30), datetime.datetime(2001,12,31), alpha=0.5, color='gray')\n",
    "    \n",
    "    #2007Q4-2009Q3 crisis\n",
    "    ax.axvspan(datetime.datetime(2007,12,31), datetime.datetime(2009,9,30), alpha=0.5, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make ax-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axsetting(ax):\n",
    "    ax.set_xticks(range(0,151,4))\n",
    "    ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "    ax.set_xticklabels(years, rotation=60)\n",
    "    ax.grid()\n",
    "    ax.set_xlim(0, 151)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing asset side & liability side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting relevant data\n",
    "df_assets = df_raw[[\"date\",\"rssdid\",\"bhcid\",  \"name\", 'year', \"quarter\",\"assets\", \"cash\"\n",
    "             ,\"fedfundsrepoasset\" ,\"securities\",\"loansnet\", \"tradingassets\"]]\n",
    "\n",
    "df_liab = df_raw[[\"date\",\"rssdid\", \"name\", 'year', \"quarter\",\"assets\", \"equity\",\"fedfundsrepoliab\" ,\n",
    "             \"deposits\",\"foreigndep\", \"otherborrowedmoney\", \"tradingliabilities\",\"subordinateddebt\", \"liabilities\"]]\n",
    "\n",
    "df_loan_loss = df_raw[[\"date\",\"rssdid\", \"name\", 'year', \"quarter\",\"assets\", \"equity\", \"loansnet\", \"loanleaselossprovision\"]]\n",
    "\n",
    "#aggregate data by year and quarter\n",
    "df_agg = df_assets.groupby([\"year\", \"quarter\", \"date\"]).sum()\n",
    "df_agg_liab = df_liab.groupby([\"year\", \"quarter\", \"date\"]).sum()\n",
    "df_loan_loss_agg = df_loan_loss.groupby([\"year\", \"quarter\", \"date\"], as_index=False).sum()\n",
    "\n",
    "#reset index\n",
    "df_agg = df_agg.reset_index()\n",
    "df_agg_liab = df_agg_liab.reset_index()\n",
    "\n",
    "#clean fedfundsrepoasset by putting average for null value\n",
    "average = (df_agg.loc[103].fedfundsrepoasset + df_agg.loc[105].fedfundsrepoasset) / 2\n",
    "df_agg.loc[104, \"fedfundsrepoasset\"] = average\n",
    "\n",
    "#fix foreign deposits missing values by filling with average of before and after\n",
    "average = (df_agg_liab.loc[28].foreigndep + df_agg_liab.loc[32].foreigndep) / 2\n",
    "df_agg_liab.loc[29, \"foreigndep\"] = average\n",
    "df_agg_liab.loc[30,\"foreigndep\"] = average\n",
    "df_agg_liab.loc[31, \"foreigndep\"] = average\n",
    "\n",
    "#fix fedfundsrepoliab in year 2002\n",
    "df_agg_liab.loc[104, \"fedfundsrepoliab\"] = df_agg_liab.loc[103].fedfundsrepoliab \n",
    "\n",
    "#computing other assets and other liabilities\n",
    "df_agg[\"otherassets\"] = df_agg[\"assets\"] - (df_agg.iloc[:,6:11].sum(axis=1))\n",
    "df_agg[\"otherliab\"] = df_agg_liab[\"assets\"] - (df_agg_liab.iloc[:,5:12].sum(axis=1))\n",
    "df_agg_liab[\"otherliab\"] = df_agg_liab[\"assets\"] - (df_agg_liab.iloc[:,5:12].sum(axis=1))\n",
    "\n",
    "#clean dataframe of nan, inf and zeros\n",
    "\n",
    "\n",
    "#getting right yscale\n",
    "df_agg_scaled = df_agg.select_dtypes(include=['float64'])/1000000000\n",
    "\n",
    "#remove liabilities, its unnessesary\n",
    "df_agg_liab.drop([\"liabilities\"], axis=1 , inplace=True)\n",
    "\n",
    "#log liabilities\n",
    "df_agg_liab_log = np.log(df_agg_liab.iloc[:,4:])\n",
    "df_agg_liab_log = pd.concat([df_agg_liab.iloc[:,:4],df_agg_liab_log], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_liab[(df_agg_liab.year==2002) & (df_agg_liab.quarter==1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assets[df_assets.rssdid==1998944.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_pct_change = df_agg.set_index(\"date\")\n",
    "\n",
    "#df_agg_pct_change.resample(\"Y\").sum().pct_change()\n",
    "#df_agg_pct_change.pct_change(freq=\"Y\").assets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_pct_change = df_agg.set_index(\"date\")\n",
    "df_agg_pct_change = df_agg_pct_change.resample(\"Y\").last()\n",
    "df_agg_pct_change[\"pct_change\"] = df_agg_pct_change.assets.pct_change()\n",
    "#df_agg_pct_change = df_agg_pct_change.iloc[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loan Loss Provision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "cycle, trend = sm.tsa.filters.hpfilter(np.log(df_loan_loss_agg.loanleaselossprovision), 1600)\n",
    "cycle = cycle*100\n",
    "cycle.plot(ax=ax)\n",
    "\n",
    "axsetting(ax)\n",
    "plot_crisis(ax)\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_LoanLossProvision_7613.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(20,15))\n",
    "ax = ax.ravel()\n",
    "\n",
    "#ax_twin = ax[1].twinx()\n",
    "\n",
    "\n",
    "\n",
    "#graph: absolute assets\n",
    "ax[0].set_ylabel(\"Trillions Dollar\")\n",
    "ax[0].set_xticks(range(0,151,4))\n",
    "ax[0].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "\n",
    "df_agg_scaled.plot.area(ax=ax[0], y=[\"cash\",\"fedfundsrepoasset\" ,\"securities\",\n",
    "                           \"loansnet\", \"tradingassets\", \"otherassets\"])\n",
    "\n",
    "\n",
    "ax[0].set_xticklabels(years, rotation=60)\n",
    "ax[0].set_xlim(0, 151)\n",
    "ax[0].legend(prop={'size': 15})\n",
    "ax[0].grid()\n",
    "\n",
    "#ax.yaxis.set_major_formatter(mlt.ticker.StrMethodFormatter(\"{x:g}\")) \n",
    "\n",
    "#graph: log(assets)\n",
    "df_agg_log = np.log(df_agg_scaled)\n",
    "'''\n",
    "ax[1].set_xticks(range(0,151,4))\n",
    "ax[1].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "df_agg_log.assets.plot(ax=ax[1], color=\"C0\")\n",
    "ax[1].set_xticklabels(years, rotation=60)\n",
    "ax[1].set_ylabel(\"log(assets)\")\n",
    "ax[1].legend([\"log(assets)\"])\n",
    "ax[1].grid()\n",
    "ax[1].set_xlim(0, 151)\n",
    "ax[1].set_title(\"Assets\")\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot growth graph\n",
    "#ax4.bar(height =df_agg_pct_change.pct_change, x=df_agg_pct_change.index)\n",
    "df_agg_pct_change[\"positive\"] = df_agg_pct_change[\"pct_change\"] > 0\n",
    "df_agg_pct_change.plot(y=\"pct_change\", kind=\"bar\", ax=ax[1], color=df_agg_pct_change.positive.map({True: 'g', False: 'r'}))\n",
    "ax[1].grid()\n",
    "ax[1].get_legend().remove()\n",
    "ax[1].set_xticks(range(0,38))\n",
    "ax[1].set_ylabel(\"Annual Growth\")\n",
    "ax[1].set_xticklabels(years, rotation=60)\n",
    "ax[1].set_title(\"Annual Asset Growth per year\")\n",
    "ax[1].yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "\n",
    "'''\n",
    "#plot defaults graph\n",
    "ax[4].set_title(\"Share of commercial banks default per year\")\n",
    "ax[4].set_ylabel(\"Share of all commercial banks\")\n",
    "ax[4].set_xlabel(\"Year\")\n",
    "x = np.arange(len(d_default_averageYear))\n",
    "ax[4].bar(x, d_default_averageYear.Percentage)\n",
    "ax[4].set_xticks(range(0,38))\n",
    "ax[4].set_xticklabels(years, rotation=60)\n",
    "ax[4].set_xlim(-1, 38)\n",
    "ax[4].grid()\n",
    "'''\n",
    "\n",
    "'''\n",
    "#plot twin axis for second graph\n",
    "ax_twin = ax[1].twinx()\n",
    "ax_twin.plot(df_agg_scaled.assets, \"y\")\n",
    "ax_twin.legend([\"assets\"], loc=[0.008, 0.7])\n",
    "ax_twin.set_ylabel(\"Trillions Dollar\")\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_AssetDistribution_7613.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle of both assets and liabilities positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# choosing asset positions\n",
    "df_agg_log_assets = df_agg_log.iloc[:, 5:11]\n",
    "\n",
    "#choosing liabilities positions\n",
    "df_agg_liab_log_positions =  df_agg_liab_log.iloc[:,5:13]\n",
    "\n",
    "#concat\n",
    "#df_agg_allpositions = pd.concat([df_agg_log_assets, df_agg_liab_log_positions], axis=1)\n",
    "#index_year = df_agg_liab_log.iloc[:,:3] \n",
    "#df_agg_allpositions = pd.concat([index_year, df_agg_allpositions], axis=1)\n",
    "\n",
    "#replace inf with nan\n",
    "df_agg_liab_log_positions.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_agg_log_assets.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8,2, figsize=(20,25), constrained_layout=True)\n",
    "ax = ax.ravel()\n",
    "\n",
    "\n",
    "#excluding other liabilities\n",
    "\n",
    "#getting positon names\n",
    "asset_positions_array = df_agg_log_assets.columns.values\n",
    "liab_positions_array = df_agg_liab_log_positions.columns.values\n",
    "\n",
    "#overall counter\n",
    "i = 0\n",
    "\n",
    "#asset positions counter\n",
    "x = 0\n",
    "\n",
    "#liabilities counter\n",
    "y = 0\n",
    "\n",
    "#dataframe to save all cycles\n",
    "df_cycle_assets = pd.DataFrame()\n",
    "df_cycle_liab = pd.DataFrame()\n",
    "\n",
    "'''\n",
    "This whole loop computes the the cycles for both asset and liabilities positions. It differentiates them,\n",
    "so asset positions are plotted on the left column and liabilities positions on the right column.\n",
    "Also, there are two cases, trading assets and trading liabilities which are treated special because of nan values\n",
    "which mess up the cycle computation. \n",
    "'''\n",
    "\n",
    "for i in range(16):\n",
    "    #when we are in the left column and there is still an asset position\n",
    "    if ((i % 2) == 0 and (x) < len(asset_positions_array)):\n",
    "        #if position is tradingassets then fix wrong values\n",
    "        if (asset_positions_array[x].startswith(\"trading\")):\n",
    "            #remove zeros for cycle estimation\n",
    "            temp_series = df_agg_log_assets[asset_positions_array[x]]\n",
    "            temp_series.dropna(inplace=True)\n",
    "            #compute cycle\n",
    "            cycle, trend = sm.tsa.filters.hpfilter(temp_series, 1600)\n",
    "            #insert zeros back into cycle\n",
    "            count_missing_values = 152 - cycle.size\n",
    "            zeros = pd.Series(np.zeros(count_missing_values))\n",
    "            cycle = pd.concat([zeros, cycle])\n",
    "            ax[i].set_title(asset_positions_array[x])\n",
    "            #save cycle\n",
    "            df_cycle_assets[asset_positions_array[x]]=cycle\n",
    "            #ax[i].set_ylabel(\"log(\" + asset_positions_array[x] + \")\")\n",
    "        #not tradingassets then calculate cycle here\n",
    "        else:\n",
    "            #replace missing values with zero\n",
    "            df_agg_log_assets[asset_positions_array[x]].fillna(0, inplace=True)\n",
    "            #compute cycle\n",
    "            cycle, trend = sm.tsa.filters.hpfilter(df_agg_log_assets[asset_positions_array[x]], 1600)\n",
    "            ax[i].set_title(asset_positions_array[x])\n",
    "            #save cycle\n",
    "            df_cycle_assets[asset_positions_array[x]]=cycle\n",
    "            #ax[i].set_ylabel(\"log(\" + asset_positions_array[x] + \")\")\n",
    "        #plot cycle    \n",
    "        ax[i].set_xticks(range(0,152,16))\n",
    "        ax[i].set_xticklabels(years16, rotation=60)\n",
    "        ax[i].plot(cycle*100)\n",
    "        ax[i].grid()\n",
    "        ax[i].yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "        #plot crisis\n",
    "        plot_crisis(ax[i])\n",
    "        #increase asset counter by one\n",
    "        x = x+1\n",
    "    #when we are in the right column \n",
    "    elif ((i % 2) != 0):\n",
    "        #if position is tradingliab then fix wrong values\n",
    "        if (liab_positions_array[y].startswith(\"trading\")):\n",
    "            #remove zeros for cycle estimation\n",
    "            temp_series = df_agg_liab_log_positions[liab_positions_array[y]]\n",
    "            temp_series.dropna(inplace=True)\n",
    "            #compute cycle\n",
    "            cycle, trend = sm.tsa.filters.hpfilter(temp_series, 1600)\n",
    "            #insert zeros back into cycle\n",
    "            count_missing_values = 152 - cycle.size\n",
    "            zeros = pd.Series(np.zeros(count_missing_values))\n",
    "            cycle = pd.concat([zeros, cycle])\n",
    "            ax[i].set_title(liab_positions_array[y])\n",
    "            #save cycle\n",
    "            df_cycle_liab[liab_positions_array[y]]=cycle\n",
    "            #ax[i].set_ylabel(\"log(\" + liab_positions_array[y] + \")\")\n",
    "        #not tradingassets then calculate cycle here\n",
    "        else:\n",
    "            #replace missing values with zero\n",
    "            df_agg_liab_log_positions[liab_positions_array[y]].fillna(0, inplace=True)\n",
    "            #compute cycle\n",
    "            cycle, trend = sm.tsa.filters.hpfilter(df_agg_liab_log_positions[liab_positions_array[y]], 1600)\n",
    "            ax[i].set_title(liab_positions_array[y])\n",
    "            #save cycle\n",
    "            df_cycle_liab[liab_positions_array[y]]=cycle\n",
    "            #ax[i].set_ylabel(\"log(\" + liab_positions_array[y] + \")\")\n",
    "        #plot cycle\n",
    "        ax[i].set_xticks(range(0,152,16))\n",
    "        ax[i].set_xticklabels(years16, rotation=60)\n",
    "        ax[i].plot(cycle*100)\n",
    "        ax[i].yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "        y = y+1\n",
    "        ax[i].grid()\n",
    "        plot_crisis(ax[i])\n",
    "    \n",
    "\n",
    "\n",
    "fig.delaxes(ax[12])\n",
    "fig.delaxes(ax[14])\n",
    "\n",
    "\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_PositionsCyclical_7613.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cyclical Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph: cyclical of log(assets)\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "cycle, trend = sm.tsa.filters.hpfilter(df_agg_log.assets, 1600)\n",
    "df_agg_log[\"cycle\"] = cycle*100\n",
    "df_agg_log.cycle.plot(ax=ax)\n",
    "orig_cycle = df_agg_log.cycle.copy()\n",
    "#plot other account cyles\n",
    "#temp_cycles = df_cycle_assets.copy()\n",
    "#temp_cycles = temp_cycles*100\n",
    "#temp_cycles.loansnet.plot(ax=ax)\n",
    "#temp_cycles.securities.plot(ax=ax)\n",
    "\n",
    "ax.set_ylabel(\"Cyclical Assets Growth\")\n",
    "ax.axhline(color=\"black\")\n",
    "ax.set_xticks(range(0,151,4))\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax.set_xticklabels(years, rotation=60)\n",
    "red_patch = mpatches.Patch(color='red',alpha=0.5)\n",
    "red_patch1 = mpatches.Patch(color='C0', lw=0.2)\n",
    "#ax.legend(handles=[red_patch, red_patch1], labels=[\"crisis\", \"detrended log(assets)\"])\n",
    "ax.legend([\"Assets Cycle\", \"Loans Cycle\", \"Securities Cycle\"])\n",
    "ax.grid()\n",
    "ax.set_xlim(0, 151)\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "plot_crisis(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_CyclicalAssets_7613.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_adjustment = df_agg.copy()\n",
    "\n",
    "new_value = temp_adjustment[temp_adjustment.date == \"2008-09-30\"].assets - 270000000\n",
    "\n",
    "#temp_adjustment.loc[temp_adjustment.date == \"2008-09-30\", [\"assets\"]] = new_value.loc[130]\n",
    "#temp_adjustment.loc[temp_adjustment.date >= \"2008-06-30\", [\"assets\"]] = temp_adjustment.loc[temp_adjustment.date >= \"2008-06-30\", [\"assets\"]] - 270000000\n",
    "#temp_adjustment.iloc[126,5] = new_value.loc[126]\n",
    "\n",
    "temp_adjustment.iloc[130:,5] = temp_adjustment.iloc[130:,5] - 270000000 #JPMorgan Chase acquires Washington Mutual\n",
    "\n",
    "temp_adjustment.iloc[127:,5] = temp_adjustment.iloc[127:,5] - 80000000 #Wachovia Corporation acquires assets of World Savings Bank\n",
    "#temp_adjustment.loc[126] = 0\n",
    "#temp_adjustment = temp_adjustment.assets[2008-09-30]\n",
    "#temp_adjustment.loc[temp_adjustment.date == \"2007-09-30\"][\"assets\"]\n",
    "temp_adjustment.iloc[130:,5] - 270000000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph: cyclical of log(assets)\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "\n",
    "#First graph\n",
    "\"\"\"\n",
    "cycle, trend = sm.tsa.filters.hpfilter(df_agg_log.assets, 1600)\n",
    "df_agg_log[\"cycle\"] = cycle*100\n",
    "df_agg_log.cycle.plot(ax=ax[0])\n",
    "\n",
    "ax[0].set_ylabel(\"Cyclical Assets Growth\")\n",
    "ax[0].axhline(color=\"black\")\n",
    "ax[0].set_xticks(range(0,151,4))\n",
    "ax[0].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax[0].set_xticklabels(years, rotation=60)\n",
    "red_patch = mpatches.Patch(color='red',alpha=0.5)\n",
    "red_patch1 = mpatches.Patch(color='C0', lw=0.2)\n",
    "#ax.legend(handles=[red_patch, red_patch1], labels=[\"crisis\", \"detrended log(assets)\"])\n",
    "ax[0].grid()\n",
    "ax[0].set_xlim(0, 151)\n",
    "ax[0].yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "ax[0].set_title(\"Asset Cycle\")\n",
    "plot_crisis(ax[0])\n",
    "\"\"\"\n",
    "#Second graph\n",
    "cycle, trend = sm.tsa.filters.hpfilter(np.log(temp_adjustment.assets), 1600)\n",
    "df_agg_log[\"cycle\"] = cycle*100\n",
    "df_agg_log.cycle.plot(ax=ax)\n",
    "\n",
    "ax.set_ylabel(\"Cyclical Assets Growth\")\n",
    "ax.axhline(color=\"black\")\n",
    "ax.set_xticks(range(0,151,4))\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax.set_xticklabels(years, rotation=60)\n",
    "red_patch = mpatches.Patch(color='red',alpha=0.5)\n",
    "red_patch1 = mpatches.Patch(color='C0', lw=0.2)\n",
    "#ax.legend(handles=[red_patch, red_patch1], labels=[\"crisis\", \"detrended log(assets)\"])\n",
    "ax.grid()\n",
    "ax.set_xlim(0, 151)\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "ax.set_title(\"Adjusted Asset Cycle\")\n",
    "plot_crisis(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_CyclicalAssetsAdjusted_7613.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_compare = { \"assets cycle\": orig_cycle, \"adjusted assets cycle\": df_agg_log.cycle}\n",
    "\n",
    "df_compare = pd.DataFrame(data=frame_compare)\n",
    "\n",
    "df_compare.set_index(df_agg.date)\n",
    "\n",
    "df_compare[\"date\"] = df_agg.date\n",
    "\n",
    "temp = df_compare[(df_compare.date>=(\"2006-12-31\")) & \n",
    "                (df_compare.date<=(\"2009-12-31\"))]\n",
    "\n",
    "temp.set_index(\"date\", inplace=True)\n",
    "\n",
    "temp.round(2)\n",
    "\n",
    "temp.to_latex(\"LatexVorlage/graphs/Tables/LatexTables/cyclicalAssetsAdjustedCompare_Crisis.tex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute correlation tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pvalues(df):\n",
    "    df = df.dropna()._get_numeric_data()\n",
    "    dfcols = pd.DataFrame(columns=df.columns)\n",
    "    pvalues = dfcols.transpose().join(dfcols, how='outer')\n",
    "    for r in df.columns:\n",
    "        for c in df.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df[r], df[c])[1], 4)\n",
    "    pvalues = pvalues.astype(\"float\")\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pvalues_2(df1, df2):\n",
    "    df1 = df1.dropna()._get_numeric_data()\n",
    "    df2 = df2.dropna()._get_numeric_data()\n",
    "    df1cols = pd.DataFrame(columns=df1.columns)\n",
    "    df2cols = pd.DataFrame(columns=df2.columns)\n",
    "    pvalues = df2cols.transpose().join(df1cols, how='outer')\n",
    "    for r in df1.columns:\n",
    "        for c in df2.columns:\n",
    "            pvalues[r][c] = round(pearsonr(df1[r], df2[c])[1], 4)\n",
    "    pvalues = pvalues.astype(\"float\")\n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply color to significant values\n",
    "def color_sig(val):\n",
    "    \n",
    "    color = 'royalblue' if val[-3:] == \"***\" else 'default'\n",
    "    \n",
    "    return 'background-color: %s' % color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color scale for colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=sns.diverging_palette(220, 20, sep=20)\n",
    "\n",
    "sns.palplot(cmap, size=0.4)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "#ax.xaxis.set_major_locator(ticker.FixedLocator([-0.5,0.5,1.5,2.5,3.5,4.5,5.5]))\n",
    "ax.xaxis.set_major_locator(ticker.IndexLocator(base=1,offset=0))\n",
    "ax.xaxis.set_major_formatter(ticker.FixedFormatter([-1,\"\",\"\",0,\"\",\"\",1 ]))\n",
    "ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "#ax.set_xticks([-0.5,0.5,1.5,2.5,3.5,4.5,5.5])\n",
    "#ax.set_xticklabels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlations\n",
    "corr_assets = df_cycle_assets.corr()\n",
    "\n",
    "corr_liab = df_cycle_liab.corr()\n",
    "\n",
    "corr_comb = df_cycle_liab.apply(lambda x: df_cycle_assets.corrwith(x))\n",
    "\n",
    "#Autocorrelations\n",
    "\n",
    "df_cycle_auto_corr = pd.DataFrame()\n",
    "\n",
    "#for total assets cycle\n",
    "temp_array = []\n",
    "for i in range(0,9):\n",
    "    temp_array.append(df_agg_log.cycle.autocorr(lag=i))\n",
    "    \n",
    "df_cycle_auto_corr[\"assets\"] = temp_array\n",
    "\n",
    "#for rest asset positions\n",
    "for column in df_cycle_assets:\n",
    "    temp_array = []\n",
    "    for i in range(0,9):\n",
    "        temp_array.append(df_cycle_assets[column].autocorr(lag=i))\n",
    "    df_cycle_auto_corr[column] = temp_array\n",
    "\n",
    "#for rest liab positions\n",
    "for column in df_cycle_liab:\n",
    "    temp_array = []\n",
    "    for i in range(0,9):\n",
    "        temp_array.append(df_cycle_liab[column].autocorr(lag=i))\n",
    "    df_cycle_auto_corr[column] = temp_array\n",
    "\n",
    "\n",
    "\n",
    "df_cycle_auto_corr.index.rename(\"lag\", inplace=True)\n",
    "\n",
    "df_cycle_auto_corr.iloc[:,0:7]\n",
    "\n",
    "df_cycle_auto_corr.iloc[:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation table for assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "corr_assets = corr_assets.round(2)\n",
    "pval = calculate_pvalues(df_cycle_assets)\n",
    "A = pval.copy()\n",
    "\n",
    "#cmap=sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "\n",
    "'''\n",
    "Alter matrix s background color based on the value of matrix A\n",
    "'''\n",
    "\n",
    "def b_g(s, cmap='coolwarm', low=0, high=0):\n",
    "    # Pass the columns from Dataframe A \n",
    "    a = A.loc[:,s.name].copy()\n",
    "    rng = a.max() - a.min()\n",
    "    norm = colors.Normalize(a.min() - (rng * low),\n",
    "                        a.max() + (rng * high))\n",
    "    normed = norm(a.values)\n",
    "    c = [colors.rgb2hex(x) for x in plt.cm.get_cmap(cmap)(normed)]\n",
    "    return ['background-color: %s' % color for color in c]\n",
    "\n",
    "\n",
    "#create three masks\n",
    "r1 = corr_assets.applymap(lambda x: '{}*'.format(x))\n",
    "r2 = corr_assets.applymap(lambda x: '{}**'.format(x))\n",
    "r3 = corr_assets.applymap(lambda x: '{}***'.format(x))\n",
    "# apply them where appropriate\n",
    "corr_assets_sig = corr_assets.copy()\n",
    "corr_assets_sig = corr_assets_sig.mask(pval<=0.1,r1)\n",
    "corr_assets_sig = corr_assets_sig.mask(pval<=0.05,r2)\n",
    "corr_assets_sig = corr_assets_sig.mask(pval<=0.01,r3)\n",
    "\n",
    "#corr_assets_sig = corr_assets.style.background_gradient(cmap='coolwarm', axis=None)\\\n",
    "#    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "#    .set_precision(2)\\\n",
    "#    .format(lambda x: '{}***'.format(x))\\\n",
    "\n",
    "\n",
    "corr_assets_sig = corr_assets_sig.style.apply(b_g,cmap='coolwarm')\n",
    "\n",
    "\n",
    "\n",
    "corr_assets_sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = calculate_pvalues(df_cycle_assets)\n",
    "\n",
    "corr_assets = corr_assets.round(2)\n",
    "\n",
    "#create three masks\n",
    "r1 = corr_assets.applymap(lambda x: '{}*'.format(x))\n",
    "r2 = corr_assets.applymap(lambda x: '{}**'.format(x))\n",
    "r3 = corr_assets.applymap(lambda x: '{}***'.format(x))\n",
    "# apply them where appropriate\n",
    "corr_assets_sig = corr_assets.copy()\n",
    "corr_assets_sig = corr_assets_sig.mask(pval<=0.1,r1)\n",
    "corr_assets_sig = corr_assets_sig.mask(pval<=0.05,r2)\n",
    "corr_assets_sig = corr_assets_sig.mask(pval<=0.01,r3)\n",
    "\n",
    "corr_assets_sig\n",
    "\n",
    "corr_assets_sig = corr_assets_sig.astype(\"str\")\n",
    "\n",
    "corr_assets_sig.to_latex(\"LatexVorlage/graphs/Tables/LatexTables/corr_assets.tex\")\n",
    "\n",
    "corr_assets_sig.style.applymap(color_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation table for liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_liab.style.background_gradient(cmap='coolwarm', axis=None)\\\n",
    "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "    .set_precision(2)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = calculate_pvalues(df_cycle_liab)\n",
    "\n",
    "corr_liab = corr_liab.round(2)\n",
    "\n",
    "#create three masks\n",
    "r1 = corr_liab.applymap(lambda x: '{}*'.format(x))\n",
    "r2 = corr_liab.applymap(lambda x: '{}**'.format(x))\n",
    "r3 = corr_liab.applymap(lambda x: '{}***'.format(x))\n",
    "# apply them where appropriate\n",
    "corr_liab_sig = corr_liab.copy()\n",
    "corr_liab_sig = corr_liab_sig.mask(pval<=0.1,r1)\n",
    "corr_liab_sig = corr_liab_sig.mask(pval<=0.05,r2)\n",
    "corr_liab_sig = corr_liab_sig.mask(pval<=0.01,r3)\n",
    "\n",
    "\n",
    "\n",
    "corr_liab_sig = corr_liab_sig.astype(\"str\")\n",
    "\n",
    "corr_liab_sig.to_latex(\"LatexVorlage/graphs/Tables/LatexTables/corr_liab.tex\")\n",
    "\n",
    "corr_liab_sig.style.applymap(color_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation table for correlation assets with liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_comb.style.background_gradient(cmap='coolwarm', axis=None)\\\n",
    "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
    "    .set_precision(2)\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = calculate_pvalues_2(df_cycle_liab, df_cycle_assets)\n",
    "\n",
    "corr_comb = corr_comb.round(2)\n",
    "\n",
    "#create three masks\n",
    "r1 = corr_comb.applymap(lambda x: '{}*'.format(x))\n",
    "r2 = corr_comb.applymap(lambda x: '{}**'.format(x))\n",
    "r3 = corr_comb.applymap(lambda x: '{}***'.format(x))\n",
    "# apply them where appropriate\n",
    "corr_comb_sig = corr_comb.copy()\n",
    "corr_comb_sig = corr_comb_sig.mask(pval<=0.1,r1)\n",
    "corr_comb_sig = corr_comb_sig.mask(pval<=0.05,r2)\n",
    "corr_comb_sig = corr_comb_sig.mask(pval<=0.01,r3)\n",
    "\n",
    "\n",
    "corr_comb_sig = corr_comb_sig.astype(\"str\")\n",
    "\n",
    "corr_comb_sig.to_latex(\"LatexVorlage/graphs/Tables/LatexTables/corr_liab_assets.tex\")\n",
    "\n",
    "corr_comb_sig.style.applymap(color_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplots for selected correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2,figsize=(10,10),  constrained_layout=True)\n",
    "ax = ax.ravel()\n",
    "\n",
    "\n",
    "sns.regplot(x=\"loansnet\", y=\"securities\",ax=ax[0], data=df_cycle_assets, robust=True, line_kws={\"color\":'firebrick'})\n",
    "sns.regplot(x=\"fedfundsrepoasset\", y=\"tradingassets\",ax=ax[1],  data=df_cycle_assets, line_kws={\"color\":'firebrick'})\n",
    "sns.regplot(x=\"fedfundsrepoasset\", y=\"loansnet\",ax=ax[2],  data=df_cycle_assets, line_kws={\"color\":'firebrick'})\n",
    "sns.regplot(x=\"deposits\", y=\"foreigndep\",ax=ax[3],  data=df_cycle_liab, line_kws={\"color\":'firebrick'})\n",
    "sns.regplot(x=df_cycle_liab.equity, y=df_cycle_assets.tradingassets,ax=ax[4], line_kws={\"color\":'firebrick'})\n",
    "sns.regplot(x=df_cycle_liab.foreigndep, y=df_cycle_assets.loansnet,ax=ax[5], line_kws={\"color\":'firebrick'})\n",
    "\n",
    "\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_scatterplots_7613.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Share of balance sheet positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shares assets\n",
    "df_agg_share_assets = pd.DataFrame()\n",
    "\n",
    "for (columnName, columnData) in df_agg.select_dtypes(include=['float64']).iteritems():\n",
    "    newcolumn = \"share\" + columnName\n",
    "    df_agg_share_assets[newcolumn] = df_agg[columnName]/df_agg.assets\n",
    "    \n",
    "    \n",
    "df_agg_share_assets.drop(['shareyear', 'sharequarter', \"sharerssdid\" , \"shareassets\", \"sharebhcid\", \"shareotherliab\"], axis=1, inplace=True)\n",
    "\n",
    "#share assets without loans\n",
    "df_agg_share_assets_noLoans = df_agg_share_assets.drop([\"shareloansnet\"], axis=1)\n",
    "\n",
    "#Shares liabs\n",
    "df_agg_share_liab = pd.DataFrame()\n",
    "\n",
    "for (columnName, columnData) in df_agg_liab.select_dtypes(include=['float64']).iteritems():\n",
    "    newcolumn = \"share\" + columnName\n",
    "    df_agg_share_liab[newcolumn] = df_agg_liab[columnName]/df_agg.assets\n",
    "    \n",
    "    \n",
    "df_agg_share_liab.drop(['shareyear', 'sharequarter', \"sharerssdid\" , \"shareassets\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Share liabs without deposits\n",
    "df_agg_share_liab_noDeposit = df_agg_share_liab.drop([\"sharedeposits\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,1,figsize=(20,20))\n",
    "ax= ax.ravel()\n",
    "\n",
    "#plot share assets subplot\n",
    "ax[0].plot(df_agg_share_assets*100)\n",
    "ax[0].set_xticklabels(years, rotation=60)\n",
    "ax[0].legend(df_agg_share_assets.columns, bbox_to_anchor=(1, 1))\n",
    "ax[0].set_xticks(range(0,151,4))\n",
    "ax[0].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax[0].grid(True)\n",
    "ax[0].set_xlim(0,151)\n",
    "ax[0].set_ylabel(\"Share account of total assets\")\n",
    "plot_crisis(ax[0])\n",
    "\n",
    "#plot without loans\n",
    "ax[1].plot(df_agg_share_assets_noLoans*100)\n",
    "ax[1].set_xticklabels(years, rotation=60)\n",
    "ax[1].legend(df_agg_share_assets_noLoans.columns, bbox_to_anchor=(1, 1))\n",
    "ax[1].set_xticks(range(0,151,4))\n",
    "ax[1].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax[1].grid(True)\n",
    "ax[1].set_xlim(0,151)\n",
    "ax[1].set_ylabel(\"Share account of total assets\")\n",
    "plot_crisis(ax[1])\n",
    "\n",
    "#plot share liab subplot\n",
    "ax[2].plot(df_agg_share_liab*100)\n",
    "ax[2].set_xticklabels(years, rotation=60)\n",
    "ax[2].legend(df_agg_share_liab.columns, bbox_to_anchor=(1, 1))\n",
    "ax[2].set_xticks(range(0,151,4))\n",
    "ax[2].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax[2].grid(True)\n",
    "ax[2].set_xlim(0,151)\n",
    "ax[2].set_ylabel(\"Share account of total liabilities\")\n",
    "plot_crisis(ax[2])\n",
    "\n",
    "\n",
    "#plot without deposits\n",
    "ax[3].plot(df_agg_share_liab_noDeposit*100)\n",
    "ax[3].set_xticklabels(years, rotation=60)\n",
    "ax[3].legend(df_agg_share_liab_noDeposit.columns, bbox_to_anchor=(1, 1))\n",
    "ax[3].set_xticks(range(0,151,4))\n",
    "ax[3].xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax[3].grid(True)\n",
    "ax[3].set_xlim(0,151)\n",
    "ax[3].set_ylabel(\"Share account of total liabilities\")\n",
    "plot_crisis(ax[3])\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_sharePositions_7613.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorenz Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_curve(X, ax):\n",
    "    X.sort()\n",
    "    X_lorenz = X.cumsum() / X.sum()\n",
    "    X_lorenz = np.insert(X_lorenz, 0, 0) \n",
    "    X_lorenz[0], X_lorenz[-1]\n",
    "    ## scatter plot of Lorenz curve\n",
    "    ax.plot(np.arange(X_lorenz.size)/(X_lorenz.size-1), X_lorenz)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(0.05))\n",
    "    plt.xticks(rotation=40)\n",
    "    ax.set_xlim(0,1)\n",
    "    ## line plot of equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "df_1980_1 = df_assets[(df_assets.year==1980) & (df_assets.quarter==1)]\n",
    "df_1985_1 = df_assets[(df_assets.year==1985) & (df_assets.quarter==1)]\n",
    "df_1990_1 = df_assets[(df_assets.year==1990) & (df_assets.quarter==1)]\n",
    "df_1995_1 = df_assets[(df_assets.year==1995) & (df_assets.quarter==1)]\n",
    "df_2000_1 = df_assets[(df_assets.year==2000) & (df_assets.quarter==1)]\n",
    "df_2005_1 = df_assets[(df_assets.year==2005) & (df_assets.quarter==1)]\n",
    "df_2013_1 = df_assets[(df_assets.year==2013) & (df_assets.quarter==1)]\n",
    "\n",
    "lorenz_curve(df_1980_1.assets.values, ax)\n",
    "#lorenz_curve(df_1985_1.assets.values, ax)\n",
    "lorenz_curve(df_1990_1.assets.values, ax)\n",
    "lorenz_curve(df_1995_1.assets.values, ax)\n",
    "lorenz_curve(df_2000_1.assets.values, ax)\n",
    "lorenz_curve(df_2005_1.assets.values, ax)\n",
    "lorenz_curve(df_2013_1.assets.values, ax)\n",
    "\n",
    "ax.plot([0,1], [0,1], color='k')\n",
    "\n",
    "ax.legend([\"1980\", \"1990\", \"1995\", \"2000\", \"2005\", \"2013\"])\n",
    "ax.grid()\n",
    "ax.set_ylabel(\"Assets(cumulative percent)\")\n",
    "ax.set_xlabel(\"Banks(cumulative percent)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_LorenzCurve_7613.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to compute gini coefficient for a given array of asset values\n",
    "'''\n",
    "def gini(arr):\n",
    "    ## first sort\n",
    "    sorted_arr = arr.copy()\n",
    "    sorted_arr.sort()\n",
    "    n = arr.size\n",
    "    coef_ = 2. / n\n",
    "    const_ = (n + 1.) / n\n",
    "    weighted_sum = sum([(i+1)*yi for i, yi in enumerate(sorted_arr)])\n",
    "    return coef_*weighted_sum/(sorted_arr.sum()) - const_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Computes for every year and month the gini coefficient\n",
    "'''\n",
    "def comp_gini(gr):\n",
    "    #gr.dropna(subset=[\"assets\"], inplace=True, axis=0)\n",
    "    coef = gini(gr.assets.values)\n",
    "    gr = gr.sum()\n",
    "    gr[\"gini\"] = coef\n",
    "    return gr\n",
    "\n",
    "df_assets_copy = df_assets.copy()\n",
    "df_assets_copy.dropna(subset=[\"assets\"], inplace=True)\n",
    "df_assets_gini = df_assets_copy.groupby(\"date\").apply(comp_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot gini coefficient with xaxis as datetime objects\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "year_locator = mlt.dates.YearLocator(1, month=3, day=31)\n",
    "years_fmt = mlt.dates.DateFormatter('%Y')\n",
    "\n",
    "ax.plot(df_assets_gini.gini)\n",
    "\n",
    "ax.xaxis.set_major_locator(year_locator)\n",
    "ax.xaxis.set_major_formatter(years_fmt)\n",
    "plt.xticks(rotation=60)\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator(4))\n",
    "ax.set_ylabel(\"Gini coefficient\")\n",
    "ax.grid()\n",
    "ax.set_xlim(datetime.datetime(1976,3,31), datetime.datetime(2013,12,31))\n",
    "        \n",
    "plot_crisis_datetime(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('LatexVorlage/graphs/DescriptiveStats/OtherAnalysis_clean_gini_7613.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative way to compute gini coefficient per year with loop\n",
    "array = []\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    temp = df_assets[(df_assets.year==float(year))]\n",
    "    temp.dropna(subset=[\"assets\"], inplace=True)\n",
    "    #print(temp.assets.isna().value_counts())\n",
    "    array.append(gini(temp.assets.values))\n",
    "\n",
    "\n",
    "s_gini_coeff = pd.Series(array, index=years)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Banks by asset categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
